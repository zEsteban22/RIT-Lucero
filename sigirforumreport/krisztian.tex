%!TEX root = lucene4IR2016workshop_report.tex
{\bf Prof. Krisztian Balog, University of Stavanger}:
The Web Search and Data Mining course is part of the Computer Science master's programme at the University of Stavanger, but it is also offered to (advanced) bachelor students.
The data mining part of the course includes data processing, classification and clustering methods.  The IR part consists of indexing, retrieval models, evaluation, link analysis, query modeling, and entity linking and retrieval.
The course is 6 hours per week, which is divided to 2 lectures (2x2 hours) and a practical session (2 hours).  

Krisztian explained that during the lectures, after presenting the theory, students get a small paper exercise sheet where they need to apply the said theory on toy-sized input data.  Examples of such exercises include constructing an index from some input text, computing term weights and scoring a small number of documents, calculating PageRank scores, etc.  They can use a calculator and/or a spreadsheet program, but the input is simple enough for pen-and-paper. The reference solutions to these exercises are made available after the class.  Student feedback has been very positive; they are really appreciative of this element in the lectures. While completing these exercises, interesting questions (both practical and theoretical) can often spring up and be discussed.
 
The practical sessions involve implementing methods from the lectures and applying them on small (but real) datasets.  Typically it happens on two levels.  First, students need to implement one or two of the simpler methods for a given problem, e.g., decision trees or Naive Bayes for classification. Second, they get to use a ready-made third-party implementation; for the previous example, it would be SVM and Random Forests (from the scikit-learn Python package). For retrieval, ElasticSearch is used; the RESTFul API is well documented and can easily be used from Python (or from any programming language for that matter).  Evaluation is a core element of these exercises, so they need to measure and compare the performance of different approaches according to some metric. 
In order to allow students to focus on the more interesting parts of the problem as opposed to more ``mechanical'' tasks (e.g., reading in data from a file), they get the skeleton of the code along with explanations as an iPython notebook, and they only need to complete the missing parts.

Finally, students have a handful of larger (obligatory) assignments throughout the semester that they need to complete in teams.  These assignments involve larger-scale datasets (note that this scale is still in accordance with academic standards, not with industrial ones).  The assignments are set up as competitions on Kaggle,\footnote{Kaggle in Class (\url{https://inclass.kaggle.com/}) is provided free of charge for academics.} with a (hard) deadline and a minimum performance threshold (e.g., a certain MAP score for a ranking task).  There are no restrictions on the choice of the programming language or libraries used.  The members of the best performing team for each assignment are rewarded with some bonus points that they can ``cash in'' during the final exam.\\

